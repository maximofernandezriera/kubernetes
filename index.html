<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Kubernetes</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="reveal.js/dist/theme/moon.css" id="theme" />

    <!-- Theme used for syntax highlighted code -->
    <link
      rel="stylesheet"
      href="reveal.js/plugin/highlight/moon.css"
      id="moon-theme"
    />
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section
          data-markdown
          data-separator="-----"
          data-separator-vertical="---"
        >
          <textarea data-template># Implantación de aplicaciones web
            
            ---

El protocolo http, o su extensión https, ha ido convirtiéndose poco a
poco en el "superprotocolo" de Internet y ha ido desplazando
paulatinamente el uso de otros protocolos.
            
            ---

De igual forma, la mayor
parte del software que se consume hoy en día se podría denominar de
forma genérica como aplicación web, aunque hay diferencias
importantes sobre la forma de presentarse, ya que no es lo mismo que una persona acceda a una aplicación a través de un navegador, a través
de una aplicación móvil o que quien acceda a la aplicación sea una
máquina.
            ---

En este curso no podemos entrar en detalle sobre las
características de estas aplicaciones web, pero sí en las
características que deben tener los sistemas que las ofrecen para que
cumplan con los requisitos esperados.
            
            ---

## Requisitos habituales de las aplicaciones web
            
            ---

Pensemos inicialmente en el caso de una aplicación interna de una
empresa que está instalada localmente y que los únicos usuarios que
tiene son la plantilla de empleados de la empresa. En ese caso, es
fácil determinar los recursos necesarios para que la aplicación
funcione de forma adecuada, porque ni el uso de la aplicación se
dispara en unos instantes, ni el número de empleados de una empresa
varía de forma abrupta.
            
            ---

Por otra parte, las actualizaciones se pueden
hacer en momentos en los que el uso es mínimo y, si es necesario una
interrupción del servicio, se puede programar para un momento
determinado en que tenga muy poco impacto. 
            
            ---
            
            Las aplicaciones de este
tipo no se suelen modificar habitualmente, sino que lo hacen de forma
bastante espaciada en el tiempo, por lo que los cambios entre una
versión y otra son significativos. Esto, que podríamos llamar
informática tradicional, también tiene un impacto importante en la
forma de desarrollar las aplicaciones que funcionan bajo este
esquema.
            
            ---

Por otra parte, una aplicación web que esté disponible en Internet,
tiene miles de millones de potenciales usuarios, que la pueden usar
las 24 horas del día y cualquier día del año. Esto tiene unas
consecuencias muy importantes, ya que es muy difícil determinar los
recursos necesarios para prestar servicios a una demanda muy variable
e idealmente, el servicio no puede interrumpirse nunca.
            
            ---
            
¿Es posible que el mismo sistema se ajuste a una demanda
que puede variar de un usuario a un millón?, ¿es posible tener un
sistema siempre actualizado y que a la vez no se pare?, ¿cómo se
aplican las actualizaciones de software?, ¿poco a poco o con grandes
saltos?. Durante este curso, veremos que precisamente esto es lo que
trata de proporcionar Kubernetes.
            
            ---

## Componentes auxiliares de un servicio web
            
            ---

El componente esencial para servir una aplicación web es un servidor
web, pero vamos a ver a continuación, que para poder proporcionar el
servicio con los requisitos anteriores, debe apoyarse en un número
importante de componentes auxiliares. En los siguientes apartados
vamos a ir viendo paso a paso la forma de ir incluyendo diferentes
componentes auxiliares y cómo esta inclusión va a ir cambiando la arquitectura de los
sistemas que proporcionan el servicio.
            
            ---

### Paso 1. Punto de partida
            
            ---

Supongamos que nuestra organización proporciona tres aplicaciones web
diferentes que son accesibles a través de las URL:

https://example.com/app1

https://example.com/app2

https://example.com/app3
            
            ---

Estas aplicaciones pueden estar desarrolladas en el mismo lenguaje o en varios diferentes (Python, Java, PHP, etc.), pueden utilizar una base
de datos, almacenamiento auxiliar y como se sirven a través de https,
es necesario gestionar los certificados x509.
            
            ---

El esquema inicial que pensaríamos para proporcionar estas tres
aplicaciones sería una máquina (física o virtual) en la que
instalaríamos el servidor web, los servidores de aplicaciones (php,
java, ...), el servidor de bases de datos, etc... tal y como aparece en la siguiente imagen:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso1.png" alt="paso1" />
            
            ---

### Paso 2. Servidor de bases de datos separado o independiente
            
            ---

Desde un punto de vista de seguridad, ubicar el servidor de bases de
datos en el mismo equipo que el servidor web es totalmente inadecuado,
ya que el servidor web, por su propia naturaleza debe permitir que
cualquier usuario acceda desde Internet y una vulnerabilidad en este
equipo podría exponer los datos que se ubican en las bases de datos a
un potencial atacante.
            
            ---
            
Además, desde el punto de vista del rendimiento
y la disponibilidad, separar los servicios en diferentes equipos hace
que no haya interacciones entre ellos y no compitan por los mismos
recursos.

            ---
            
<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso2.png" alt="paso2" />
            
            ---

### Paso 3. Servidores de aplicaciones en equipos separados
            
            ---

El coste computacional mayor en una aplicación web suele recaer en los
servidores de aplicaciones, que son los que ejecutan código complejo, mientras que el servidor web se limita a servir el contenido generado
por estos servidores de aplicaciones o los ficheros estáticos del sitio web. 

            ---
            
Al servir tres aplicaciones web diferentes desde el mismo
equipo, podemos tener importantes interacciones entre ellas y que un
aumento de uso de una aplicación, repercuta negativamente en las
otras. 
            ---
            
            Es por esto, por lo que se puede separar estos servidores de
aplicación en equipos dedicados para cada una de ellas. La función del
servidor web en este caso, se acerca más a la de un proxy inverso, que
pasa la petición web a un equipo interno (el servidor de
aplicaciones).
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso3.png" alt="paso3" />
            
            ---

### Paso 4. Caché SQL
            
            ---

Los servidores de aplicaciones consultan continuamente a los
servidores de bases de datos y cada consulta conlleva un importante
coste computacional y una ralentización de la respuesta. 
            
            ---
            
            Si la misma
consulta ya se ha realizado antes, se puede acelerar mucho la
velocidad de respuesta con menor coste computacional utilizando un
servicio de caché SQL, de manera que los servidores de aplicaciones se
configuran para consultar al servidor caché, que servirá directamente
la respuesta si ya lo ha hecho anteriormente, o consultará al servidor
de bases de datos en caso necesario. 
            
            ---
            
            Memcached o redis son dos
opciones muy utilizadas como caché SQL.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso4.png"
alt="paso4" />
            
            ---

### Paso 5. Caché HTTP
            
            ---

Al igual que se puede cachear la respuesta del servidor de bases de
datos, se puede hacer lo mismo con la del servidor de aplicaciones o
el servidor web. 
            
            ---
            
            Dependiendo del servidor de aplicaciones, se puede
ubicar este componente delante del servidor web o entre éste y el
servidor de aplicaciones. Dicho de otro modo, podemos cachear http o
algún otro protocolo como CGI, WSGI, etc. Un software muy conocido de
caché http es varnish.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso5.png"
alt="paso5" />
            
            ---

### Paso 6. Varios servidores de aplicaciones
            
            ---

Si la demanda de alguna de las aplicaciones varía de forma importante,
se puede utilizar escalado horizontal, aumentando el número de nodos
de estos servidores de aplicaciones a la demanda de cada momento.
            
            ---
            
            Esto
conlleva dos importantes modificaciones, el almacenamiento entre los
servidores de aplicación de la misma aplicación tiene que estar
distribuido de forma que garantice el uso concurrente y se deben
repartir las peticiones a los diferentes servidores de aplicación a
través de un balanceador de carga.
            
            ---
            

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso6.png"
alt="paso6" />
            
            ---

### Paso 7. Alta disponibilidad en el resto de componentes
            
            ---

No solo se pueden escalar horizontalmente los servidores de
aplicaciones, sino que si queremos ofrecer realmente alta
disponibilidad en todos los niveles, debemos crear una arquitectura en
la que la disponibilidad nunca dependa de uno solo nodo y el sistema
pueda responder siempre ante incidencias puntuales en cualquier nivel.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso7.png"
alt="paso7" />
            
            ---


### Paso 8. Microservicios y aplicaciones "tradicionales"
            
            ---

Una de las opciones que se considera más adecuada hoy en día para el
desarrollo y puesta en producción de aplicaciones web es la utilización de microservicios. Con este enfoque los propios componentes de la aplicación se
separan en múltiples componentes que se ejecutan en nodos
independientes (típicamente contenedores) y se comunican unos con
otros a través de servicios en red que ofrecen al resto.
            
            ---

Estos microservicios no solo incluirían de forma independiente los
componentes que hemos explicado hasta ahora, sino que principalmente
se refiere a la separación de los componentes internos de la
aplicación en diferentes microservicios.
           

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso8.png"
alt="paso8" />
            
            ---

### Paso 9. Escalabilidad en los microservicios
            
            ---

Al ofrecer microservicios no podemos tener dependencia de un solo
nodo, por lo que al igual que en los pasos anteriores, se debe ofrecer
la posibilidad de escalar cualquier componente a la demanda y que el
sistema globalmente pueda responder ante cualquier error puntual.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso9.png"
alt="paso9" />
            
            ---

### Paso 10. Microservicios en todas las aplicaciones
            
            ---

En lugar de utilizar microservicios en una aplicación, podríamos
utilizarlos en todas, pero manteniendo los componentes auxiliares
gestionados aparte.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso10.png"
alt="paso10" />
            
            ---

### Paso 11. Todo en microservicios

O podríamos tener todo definido internamente en microservicios, tanto
los componentes de cada aplicación, como los componentes auxiliares.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso11.png"
alt="paso11" />
            
            ---

## Contenedores
            
            ---

En parte por lo que hemos explicado aquí, y en parte por las ventajas
que proporciona en el desarrollo de software y en el rápido
despliegue, muchos de los componentes que hemos presentado se
ejecutan no sobre máquinas virtuales o físicas, sino que lo hacen
sobre contenedores de aplicaciones tipo docker (hoy en día se plantean
otras alternativas como podman o containerd, pero no vamos a entrar en
esa explicación). 
            
            ---     
            
            
Docker es capaz de gestionar esos contenedores de
forma ágil y rápida, pero no tiene funcionalidad para ejecutar
escenarios tan complejos como los anteriores, que además se
ejecutarían lógicamente en diferentes nodos físicos o virtuales (que a
su vez ejecutarían docker para los componentes de la aplicación).
            
            ---

## Conclusión
            
            ---

Esto no son más que un conjunto de componentes y una explicación muy
rápida de ellos, el orden y la ubicación de ellos es variable en
función del caso de uso, pero en cualquier caso queríamos presentarlos
aquí para tener una visión global de hacia dónde vamos. Algo que
claramente podemos ver es que la gestión de este tipo de aplicaciones
se convierte pronto en algo muy complejo, por lo que necesitamos
apoyarnos en algún software que controle y gestione de forma adecuada
estos sistemas tan complejos.
            
            ---
            
            # Docker y su evolución histórica
            
            ---

Docker es una empresa ([Docker Inc.](https://www.docker.com/)) que
desarrolla un software con el mismo nombre, de forma más concreta el software denominado ([docker
engine](https://www.docker.com/products/container-runtime)), que ha
supuesto una revolución en el desarrollo de software, muy ligado al
uso de contenedores de aplicaciones, a las aplicaciones web y al
desarrollo ágil.
            
            ---

Docker permite gestionar contenedores a alto nivel, proporcionando
todas las capas y funcionalidad adicional y, lo más importante de todo,
es que proporciona un nuevo paradigma en la forma de distribuir las
aplicaciones, ya que se crean imágenes en contenedores que se
distribuyen, de manera que el contenedor que se ha desarrollado es
idéntico al que se utiliza en producción y deja de instalarse la
aplicación de forma tradicional.
            
            ---

## Componentes de docker

Docker engine tiene los componentes que a *grosso modo* se presentan a
continuación:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/docker.png" alt="docker" />

En la imagen se han destacado los componentes que son relevantes desde
el punto de vista de este curso, ya que como veremos más adelante,
docker podría ser un componente esencial de Kubernetes, pero realmente
no lo es completo, solo containerd y los elementos que éste
proporciona lo son, ya que k8s utiliza su propia API, su propia línea
de comandos y gestiona el almacenamiento y las redes de forma
independiente a docker.
            
            ---

## Evolución del proyecto docker
            
            ---

Docker tuvo un enorme éxito y una gran repercusión, pero la empresa
que lo desarrolla siempre se ha movido en el dilema de cómo sacar
rendimiento económico a su software, que al ser desarrollado bajo
licencia libre, no proporciona beneficio como tal. Este dilema se ha
tratado de resolver con modificaciones en la licencia o con doble
licenciamiento (docker CE y docker EE en estos momentos), pero esto a
su vez ha propiciado que otras empresas desarrollasen alternativas a
docker para no depender en el futuro de una empresa sin un modelo de
negocio claro y ante posibles modificaciones de la licencia libre de
docker.

            ---
            
Los cambios más significativos que han ocurrido en docker se enumeran
a continuación:
            
            ---

* [Moby](https://github.com/moby/moby) Docker engine se desarrolla
  ahora como proyecto de software libre independiente de Docker Inc. denominándose Moby. De este proyecto se surten las distribuciones de
  linux para desarrollar los paquetes docker.io
            
            ---

* [Docker Engine](https://www.docker.com/products/container-runtime)
  Versión desarrollada por Docker Inc.
            
            ---

* [runC](https://github.com/opencontainers/runc) Componente que
  ejecuta los contenedores a bajo nivel. Actualmente desarrollado por
  OCI
            
            ---

* [containerd](https://github.com/containerd/containerd) Componente
  que ejecuta los contenedores e interactúa con las
  imágenes. Actualmente desarrollado por la CNCF.
            
            ---

## Limitaciones de docker (docker engine)

Docker (docker engine) gestiona completamente la ejecución de un
contenedor en un determinado nodo a partir de una imagen, pero no
proporciona toda la funcionalidad que necesitamos para ejecutar
aplicaciones en entornos en producción.
            
            ---

Existen diferentes preguntas
que nos podemos hacer acerca de esto :
            
            ---

* ¿Qué hacemos con los cambios entre versiones?
* ¿Cómo hacemos los cambios en producción?
* ¿Cómo se balancea la carga entre múltiples contenedores iguales?
* ¿Cómo se conectan contenedores que se ejecuten en diferentes
demonios de docker?
* ¿Se puede hacer una actualización de una aplicación sin
interrupción?
* ¿Se puede variar a demanda el número de réplicas de un determinado
contenedor?
* ¿Es posible mover la carga entre diferentes nodos?
            
            ---

Las respuestas a estas preguntas no pueden venir de docker engine, ya
que no es un software desarrollado para eso, tiene que venir de algún software
que pueda utilizar docker o parte de él y que sea capaz de comunicar
múltiples nodos para proporcionar de forma coordinada estas
funcionalidades. Ese software se conoce de forma genérica como
**orquestador de contenedores**.
            
            ---
           
#Instalación de Kubernetes. 
## Alternativas para instalación simple de k8s
            
            ---

Kubernetes es un software pensado para poner en producción
aplicaciones más o menos complejas que se ejecutan sobre contenedores,
garantizando su disponibilidad, escalabilidad y actualización sin
interrupciones.
            
            ---

En un entorno en producción no se instala Kubernetes
en un solo equipo (nodo), sino que creamos un cluster de nodos que
permita garantizar el funcionamiento ininterrumpido de las
aplicaciones incluso en el caso de que uno o varios de los nodos del
cluster tengan algún tipo de incidencia.
            
            ---

Configurar y actualizar un cluster de Kubernetes es una tarea
compleja, pero existe la posibilidad de instalar de forma fácil un
cluster de Kubernetes compuesto por un solo nodo o un conjunto pequeño
para algunos casos de uso, como en el caso de la instalación de un
entorno de desarrollo o aprendizaje, que es precisamente la situación
que tenemos en nuestro caso.
            
            ---
            
 Estas instalaciones de Kubernetes no son
adecuadas para entornos en producción, pero nos permiten utilizar
Kubernetes de forma sencilla, conocer los objetos y atacar la API sin
tener que utilizar una instalación más compleja o costosa.
            
            ---

# minikube

Minikube permite desplegar localmente un "cluster" de Kubernetes con
un solo nodo. Minikube es un proyecto oficial de Kubernetes y es
probablemente la solución más adecuada para aprender a usar k8s, ya
que es un proyecto maduro y muy sencillo de instalar. Los requisitos
mínimos para instalar minikube en nuestro equipo son:
            
            ---

* 2 CPUs
* 2GiB de memoria
* 20GiB de espacio libre en disco
* Un sistema de virtualización o de contenedores instalado:
  * Docker
  * Hyperkit
  * Hyper-V
  * KVM
  * Parallels
  * Podman
  * VirtualBox
  * VMWare
            
            ---

Minikube instalará un nodo de Kubernetes en el sistema de
virtualización/contenedores que prefiramos, siendo unas opciones más adecuadas que otras dependiendo del sistema operativo de nuestro equipo, tal como se muestra
en
[https://minikube.sigs.k8s.io/docs/drivers/](https://minikube.sigs.k8s.io/docs/drivers/). En
versiones recientes, es posible aumentar el número de nodos del
cluster de minikube, aunque para el objetivo de este curso no es
necesario y haremos la instalación estándar de un solo nodo.
            
            ---

Los detalles para la instalación local de minikube los explicamos en
la siguiente sección, ya que va a ser el método recomendado para
realizar este curso.
            
            ---

# kubeadm

kubeadm es una solución más realista que minikube si se
instala un cluster de Kubernetes con varios nodos. Su instalación no es especialmente compleja, pero no está tan automatizada
como minikube y necesita más recursos y tiempo para
configurarlo. kubeadm es una opción muy interesante cuando queremos
ver de forma detallada la diferencia entre lo que se ejecuta en el
nodo controlador y en los nodos workers, que no se puede apreciar en
minikube.
            
            ---

La instalación de kubeadm se realiza típicamente en varias máquinas
virtuales o varias instancias de nube y dejamos un par de enlaces para
quienes estén más interesados en indagar en este software:
            
            ---

* [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
* [https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/](https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/)

            ---
# kind

kind (kubernetes in docker) es un proyecto oficial de Kubernetes más
reciente que los dos anteriores y que permite desplegar un cluster de
Kubernetes con varios nodos sobre docker. Es también muy interesante
como opción de instalación local y de forma análoga al anterior,
dejamos un par de enlaces para quienes estén interesados en probarlo:
            
            ---

* [https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/)
* [https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/](https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/)
            
            ---

# k3s

A diferencia de las opciones anteriores, k3s es una distribución de
Kubernetes que sí está pensada para poner en producción, pero en unas
circunstancias peculiares como son su uso para IoT, edge computing y
en general para configurar clusters de Kubernetes en sistemas de pocos
recursos (k3s es por ejemplo la opción más adecuada para usar
Kubernetes en la arquitectura arm). k3s no es un proyecto oficial de
Kubernetes, sino que lo comenzó a desarrollar la empresa
[Rancher](https://rancher.com/) y hoy en día lo mantiene la [Cloud
Native Computing Foundation](https://www.cncf.io/).
            
            ---

Los pasos para la instalaciónde k3s están disponibles en:

* [https://rancher.com/docs/k3s/latest/en/installation/](https://rancher.com/docs/k3s/latest/en/installation/)
            
            ---

# Conclusión

Aunque existen múltiples opciones de instalación de Kubernetes, en este curso
utilizaremos minikube que es el proyecto más maduro y que consideramos
más adecuado para comenzar y centrarnos directamente en el uso de
Kubernetes, obviando inicialmente los detalles de la instalación de
Kubernetes, que realmente es un proceso complejo y que no es lo más
adecuado para empezar.
            
          </textarea>
        </section>
      </div>
    </div>

    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script src="reveal.js/plugin/zoom/zoom.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom],
      });
    </script>
  </body>
</html>
