<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Kubernetes</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="reveal.js/dist/theme/moon.css" id="theme" />

    <!-- Theme used for syntax highlighted code -->
    <link
      rel="stylesheet"
      href="reveal.js/plugin/highlight/moon.css"
      id="moon-theme"
    />
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section
          data-markdown
          data-separator="-----"
          data-separator-vertical="---"
        >
          <textarea data-template># Implantación de aplicaciones web
            
            ---

El protocolo http, o su extensión https, ha ido convirtiéndose poco a
poco en el "superprotocolo" de Internet y ha ido desplazando
paulatinamente el uso de otros protocolos.
            
            ---

De igual forma, la mayor
parte del software que se consume hoy en día se podría denominar de
forma genérica como aplicación web, aunque hay diferencias
importantes sobre la forma de presentarse, ya que no es lo mismo que una persona acceda a una aplicación a través de un navegador, a través
de una aplicación móvil o que quien acceda a la aplicación sea una
máquina.
            ---

En este curso no podemos entrar en detalle sobre las
características de estas aplicaciones web, pero sí en las
características que deben tener los sistemas que las ofrecen para que
cumplan con los requisitos esperados.
            
            ---

## Requisitos habituales de las aplicaciones web
            
            ---

Pensemos inicialmente en el caso de una aplicación interna de una
empresa que está instalada localmente y que los únicos usuarios que
tiene son la plantilla de empleados de la empresa. En ese caso, es
fácil determinar los recursos necesarios para que la aplicación
funcione de forma adecuada, porque ni el uso de la aplicación se
dispara en unos instantes, ni el número de empleados de una empresa
varía de forma abrupta.
            
            ---

Por otra parte, las actualizaciones se pueden
hacer en momentos en los que el uso es mínimo y, si es necesario una
interrupción del servicio, se puede programar para un momento
determinado en que tenga muy poco impacto. 
            
            ---
            
            Las aplicaciones de este
tipo no se suelen modificar habitualmente, sino que lo hacen de forma
bastante espaciada en el tiempo, por lo que los cambios entre una
versión y otra son significativos. Esto, que podríamos llamar
informática tradicional, también tiene un impacto importante en la
forma de desarrollar las aplicaciones que funcionan bajo este
esquema.
            
            ---

Por otra parte, una aplicación web que esté disponible en Internet,
tiene miles de millones de potenciales usuarios, que la pueden usar
las 24 horas del día y cualquier día del año. Esto tiene unas
consecuencias muy importantes, ya que es muy difícil determinar los
recursos necesarios para prestar servicios a una demanda muy variable
e idealmente, el servicio no puede interrumpirse nunca.
            
            ---
            
¿Es posible que el mismo sistema se ajuste a una demanda
que puede variar de un usuario a un millón?, ¿es posible tener un
sistema siempre actualizado y que a la vez no se pare?, ¿cómo se
aplican las actualizaciones de software?, ¿poco a poco o con grandes
saltos?. Durante este curso, veremos que precisamente esto es lo que
trata de proporcionar Kubernetes.
            
            ---

## Componentes auxiliares de un servicio web
            
            ---

El componente esencial para servir una aplicación web es un servidor
web, pero vamos a ver a continuación, que para poder proporcionar el
servicio con los requisitos anteriores, debe apoyarse en un número
importante de componentes auxiliares. En los siguientes apartados
vamos a ir viendo paso a paso la forma de ir incluyendo diferentes
componentes auxiliares y cómo esta inclusión va a ir cambiando la arquitectura de los
sistemas que proporcionan el servicio.
            
            ---

### Paso 1. Punto de partida
            
            ---

Supongamos que nuestra organización proporciona tres aplicaciones web
diferentes que son accesibles a través de las URL:

https://example.com/app1

https://example.com/app2

https://example.com/app3
            
            ---

Estas aplicaciones pueden estar desarrolladas en el mismo lenguaje o en varios diferentes (Python, Java, PHP, etc.), pueden utilizar una base
de datos, almacenamiento auxiliar y como se sirven a través de https,
es necesario gestionar los certificados x509.
            
            ---

El esquema inicial que pensaríamos para proporcionar estas tres
aplicaciones sería una máquina (física o virtual) en la que
instalaríamos el servidor web, los servidores de aplicaciones (php,
java, ...), el servidor de bases de datos, etc... tal y como aparece en la siguiente imagen:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso1.png" alt="paso1" />
            
            ---

### Paso 2. Servidor de bases de datos separado o independiente
            
            ---

Desde un punto de vista de seguridad, ubicar el servidor de bases de
datos en el mismo equipo que el servidor web es totalmente inadecuado,
ya que el servidor web, por su propia naturaleza debe permitir que
cualquier usuario acceda desde Internet y una vulnerabilidad en este
equipo podría exponer los datos que se ubican en las bases de datos a
un potencial atacante.
            
            ---
            
Además, desde el punto de vista del rendimiento
y la disponibilidad, separar los servicios en diferentes equipos hace
que no haya interacciones entre ellos y no compitan por los mismos
recursos.

            ---
            
<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso2.png" alt="paso2" />
            
            ---

### Paso 3. Servidores de aplicaciones en equipos separados
            
            ---

El coste computacional mayor en una aplicación web suele recaer en los
servidores de aplicaciones, que son los que ejecutan código complejo, mientras que el servidor web se limita a servir el contenido generado
por estos servidores de aplicaciones o los ficheros estáticos del sitio web. 

            ---
            
Al servir tres aplicaciones web diferentes desde el mismo
equipo, podemos tener importantes interacciones entre ellas y que un
aumento de uso de una aplicación, repercuta negativamente en las
otras. 
            ---
            
            Es por esto, por lo que se puede separar estos servidores de
aplicación en equipos dedicados para cada una de ellas. La función del
servidor web en este caso, se acerca más a la de un proxy inverso, que
pasa la petición web a un equipo interno (el servidor de
aplicaciones).
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso3.png" alt="paso3" />
            
            ---

### Paso 4. Caché SQL
            
            ---

Los servidores de aplicaciones consultan continuamente a los
servidores de bases de datos y cada consulta conlleva un importante
coste computacional y una ralentización de la respuesta. 
            
            ---
            
            Si la misma
consulta ya se ha realizado antes, se puede acelerar mucho la
velocidad de respuesta con menor coste computacional utilizando un
servicio de caché SQL, de manera que los servidores de aplicaciones se
configuran para consultar al servidor caché, que servirá directamente
la respuesta si ya lo ha hecho anteriormente, o consultará al servidor
de bases de datos en caso necesario. 
            
            ---
            
            Memcached o redis son dos
opciones muy utilizadas como caché SQL.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso4.png"
alt="paso4" />
            
            ---

### Paso 5. Caché HTTP
            
            ---

Al igual que se puede cachear la respuesta del servidor de bases de
datos, se puede hacer lo mismo con la del servidor de aplicaciones o
el servidor web. 
            
            ---
            
            Dependiendo del servidor de aplicaciones, se puede
ubicar este componente delante del servidor web o entre éste y el
servidor de aplicaciones. Dicho de otro modo, podemos cachear http o
algún otro protocolo como CGI, WSGI, etc. Un software muy conocido de
caché http es varnish.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso5.png"
alt="paso5" />
            
            ---

### Paso 6. Varios servidores de aplicaciones
            
            ---

Si la demanda de alguna de las aplicaciones varía de forma importante,
se puede utilizar escalado horizontal, aumentando el número de nodos
de estos servidores de aplicaciones a la demanda de cada momento.
            
            ---
            
            Esto
conlleva dos importantes modificaciones, el almacenamiento entre los
servidores de aplicación de la misma aplicación tiene que estar
distribuido de forma que garantice el uso concurrente y se deben
repartir las peticiones a los diferentes servidores de aplicación a
través de un balanceador de carga.
            
            ---
            

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso6.png"
alt="paso6" />
            
            ---

### Paso 7. Alta disponibilidad en el resto de componentes
            
            ---

No solo se pueden escalar horizontalmente los servidores de
aplicaciones, sino que si queremos ofrecer realmente alta
disponibilidad en todos los niveles, debemos crear una arquitectura en
la que la disponibilidad nunca dependa de uno solo nodo y el sistema
pueda responder siempre ante incidencias puntuales en cualquier nivel.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso7.png"
alt="paso7" />
            
            ---


### Paso 8. Microservicios y aplicaciones "tradicionales"
            
            ---

Una de las opciones que se considera más adecuada hoy en día para el
desarrollo y puesta en producción de aplicaciones web es la utilización de microservicios. Con este enfoque los propios componentes de la aplicación se
separan en múltiples componentes que se ejecutan en nodos
independientes (típicamente contenedores) y se comunican unos con
otros a través de servicios en red que ofrecen al resto.
            
            ---

Estos microservicios no solo incluirían de forma independiente los
componentes que hemos explicado hasta ahora, sino que principalmente
se refiere a la separación de los componentes internos de la
aplicación en diferentes microservicios.
           

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso8.png"
alt="paso8" />
            
            ---

### Paso 9. Escalabilidad en los microservicios
            
            ---

Al ofrecer microservicios no podemos tener dependencia de un solo
nodo, por lo que al igual que en los pasos anteriores, se debe ofrecer
la posibilidad de escalar cualquier componente a la demanda y que el
sistema globalmente pueda responder ante cualquier error puntual.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso9.png"
alt="paso9" />
            
            ---

### Paso 10. Microservicios en todas las aplicaciones
            
            ---

En lugar de utilizar microservicios en una aplicación, podríamos
utilizarlos en todas, pero manteniendo los componentes auxiliares
gestionados aparte.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso10.png"
alt="paso10" />
            
            ---

### Paso 11. Todo en microservicios

O podríamos tener todo definido internamente en microservicios, tanto
los componentes de cada aplicación, como los componentes auxiliares.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso11.png"
alt="paso11" />
            
            ---

## Contenedores
            
            ---

En parte por lo que hemos explicado aquí, y en parte por las ventajas
que proporciona en el desarrollo de software y en el rápido
despliegue, muchos de los componentes que hemos presentado se
ejecutan no sobre máquinas virtuales o físicas, sino que lo hacen
sobre contenedores de aplicaciones tipo docker (hoy en día se plantean
otras alternativas como podman o containerd, pero no vamos a entrar en
esa explicación). 
            
            ---     
            
            
Docker es capaz de gestionar esos contenedores de
forma ágil y rápida, pero no tiene funcionalidad para ejecutar
escenarios tan complejos como los anteriores, que además se
ejecutarían lógicamente en diferentes nodos físicos o virtuales (que a
su vez ejecutarían docker para los componentes de la aplicación).
            
            ---

## Conclusión
            
            ---

Esto no son más que un conjunto de componentes y una explicación muy
rápida de ellos, el orden y la ubicación de ellos es variable en
función del caso de uso, pero en cualquier caso queríamos presentarlos
aquí para tener una visión global de hacia dónde vamos. Algo que
claramente podemos ver es que la gestión de este tipo de aplicaciones
se convierte pronto en algo muy complejo, por lo que necesitamos
apoyarnos en algún software que controle y gestione de forma adecuada
estos sistemas tan complejos.
            
            ---
            
            # Docker y su evolución histórica
            
            ---

Docker es una empresa ([Docker Inc.](https://www.docker.com/)) que
desarrolla un software con el mismo nombre, de forma más concreta el software denominado ([docker
engine](https://www.docker.com/products/container-runtime)), que ha
supuesto una revolución en el desarrollo de software, muy ligado al
uso de contenedores de aplicaciones, a las aplicaciones web y al
desarrollo ágil.
            
            ---

Docker permite gestionar contenedores a alto nivel, proporcionando
todas las capas y funcionalidad adicional y, lo más importante de todo,
es que proporciona un nuevo paradigma en la forma de distribuir las
aplicaciones, ya que se crean imágenes en contenedores que se
distribuyen, de manera que el contenedor que se ha desarrollado es
idéntico al que se utiliza en producción y deja de instalarse la
aplicación de forma tradicional.
            
            ---

## Componentes de docker

Docker engine tiene los componentes que a *grosso modo* se presentan a
continuación:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/docker.png" alt="docker" />

En la imagen se han destacado los componentes que son relevantes desde
el punto de vista de este curso, ya que como veremos más adelante,
docker podría ser un componente esencial de Kubernetes, pero realmente
no lo es completo, solo containerd y los elementos que éste
proporciona lo son, ya que k8s utiliza su propia API, su propia línea
de comandos y gestiona el almacenamiento y las redes de forma
independiente a docker.
            
            ---

## Evolución del proyecto docker
            
            ---

Docker tuvo un enorme éxito y una gran repercusión, pero la empresa
que lo desarrolla siempre se ha movido en el dilema de cómo sacar
rendimiento económico a su software, que al ser desarrollado bajo
licencia libre, no proporciona beneficio como tal. Este dilema se ha
tratado de resolver con modificaciones en la licencia o con doble
licenciamiento (docker CE y docker EE en estos momentos), pero esto a
su vez ha propiciado que otras empresas desarrollasen alternativas a
docker para no depender en el futuro de una empresa sin un modelo de
negocio claro y ante posibles modificaciones de la licencia libre de
docker.

            ---
            
Los cambios más significativos que han ocurrido en docker se enumeran
a continuación:
            
            ---

* [Moby](https://github.com/moby/moby) Docker engine se desarrolla
  ahora como proyecto de software libre independiente de Docker Inc. denominándose Moby. De este proyecto se surten las distribuciones de
  linux para desarrollar los paquetes docker.io
            
            ---

* [Docker Engine](https://www.docker.com/products/container-runtime)
  Versión desarrollada por Docker Inc.
            
            ---

* [runC](https://github.com/opencontainers/runc) Componente que
  ejecuta los contenedores a bajo nivel. Actualmente desarrollado por
  OCI
            
            ---

* [containerd](https://github.com/containerd/containerd) Componente
  que ejecuta los contenedores e interactúa con las
  imágenes. Actualmente desarrollado por la CNCF.
            
            ---

## Limitaciones de docker (docker engine)

Docker (docker engine) gestiona completamente la ejecución de un
contenedor en un determinado nodo a partir de una imagen, pero no
proporciona toda la funcionalidad que necesitamos para ejecutar
aplicaciones en entornos en producción.
            
            ---

Existen diferentes preguntas
que nos podemos hacer acerca de esto :
            
            ---

* ¿Qué hacemos con los cambios entre versiones?
* ¿Cómo hacemos los cambios en producción?
* ¿Cómo se balancea la carga entre múltiples contenedores iguales?
* ¿Cómo se conectan contenedores que se ejecuten en diferentes
demonios de docker?
* ¿Se puede hacer una actualización de una aplicación sin
interrupción?
* ¿Se puede variar a demanda el número de réplicas de un determinado
contenedor?
* ¿Es posible mover la carga entre diferentes nodos?
            
            ---

Las respuestas a estas preguntas no pueden venir de docker engine, ya
que no es un software desarrollado para eso, tiene que venir de algún software
que pueda utilizar docker o parte de él y que sea capaz de comunicar
múltiples nodos para proporcionar de forma coordinada estas
funcionalidades. Ese software se conoce de forma genérica como
**orquestador de contenedores**.
            
            ---
           
## Instalación de Kubernetes.
            
            ---
## Alternativas para instalación simple de k8s
            
            ---

Kubernetes es un software pensado para poner en producción
aplicaciones más o menos complejas que se ejecutan sobre contenedores,
garantizando su disponibilidad, escalabilidad y actualización sin
interrupciones.
            
            ---

En un entorno en producción no se instala Kubernetes
en un solo equipo (nodo), sino que creamos un cluster de nodos que
permita garantizar el funcionamiento ininterrumpido de las
aplicaciones incluso en el caso de que uno o varios de los nodos del
cluster tengan algún tipo de incidencia.
            
            ---

Configurar y actualizar un cluster de Kubernetes es una tarea
compleja, pero existe la posibilidad de instalar de forma fácil un
cluster de Kubernetes compuesto por un solo nodo o un conjunto pequeño
para algunos casos de uso, como en el caso de la instalación de un
entorno de desarrollo o aprendizaje, que es precisamente la situación
que tenemos en nuestro caso.
            
            ---
            
 Estas instalaciones de Kubernetes no son
adecuadas para entornos en producción, pero nos permiten utilizar
Kubernetes de forma sencilla, conocer los objetos y atacar la API sin
tener que utilizar una instalación más compleja o costosa.
            
            ---

# minikube

Minikube permite desplegar localmente un "cluster" de Kubernetes con
un solo nodo. Minikube es un proyecto oficial de Kubernetes y es
probablemente la solución más adecuada para aprender a usar k8s, ya
que es un proyecto maduro y muy sencillo de instalar. Los requisitos
mínimos para instalar minikube en nuestro equipo son:
            
            ---

* 2 CPUs
* 2GiB de memoria
* 20GiB de espacio libre en disco
* Un sistema de virtualización o de contenedores instalado:
  * Docker
  * Hyperkit
  * Hyper-V
  * KVM
  * Parallels
  * Podman
  * VirtualBox
  * VMWare
            
            ---

Minikube instalará un nodo de Kubernetes en el sistema de
virtualización/contenedores que prefiramos, siendo unas opciones más adecuadas que otras dependiendo del sistema operativo de nuestro equipo, tal como se muestra
en
[https://minikube.sigs.k8s.io/docs/drivers/](https://minikube.sigs.k8s.io/docs/drivers/). En
versiones recientes, es posible aumentar el número de nodos del
cluster de minikube, aunque para el objetivo de este curso no es
necesario y haremos la instalación estándar de un solo nodo.
            
            ---

Los detalles para la instalación local de minikube los explicamos en
la siguiente sección, ya que va a ser el método recomendado para
realizar este curso.
            
            ---

# kubeadm

kubeadm es una solución más realista que minikube si se
instala un cluster de Kubernetes con varios nodos. Su instalación no es especialmente compleja, pero no está tan automatizada
como minikube y necesita más recursos y tiempo para
configurarlo. kubeadm es una opción muy interesante cuando queremos
ver de forma detallada la diferencia entre lo que se ejecuta en el
nodo controlador y en los nodos workers, que no se puede apreciar en
minikube.
            
            ---

La instalación de kubeadm se realiza típicamente en varias máquinas
virtuales o varias instancias de nube y dejamos un par de enlaces para
quienes estén más interesados en indagar en este software:
            
            ---

* [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
* [https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/](https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/)

            ---
# kind

kind (kubernetes in docker) es un proyecto oficial de Kubernetes más
reciente que los dos anteriores y que permite desplegar un cluster de
Kubernetes con varios nodos sobre docker. Es también muy interesante
como opción de instalación local y de forma análoga al anterior,
dejamos un par de enlaces para quienes estén interesados en probarlo:
            
            ---

* [https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/)
* [https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/](https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/)
            
            ---

# k3s

A diferencia de las opciones anteriores, k3s es una distribución de
Kubernetes que sí está pensada para poner en producción, pero en unas
circunstancias peculiares como son su uso para IoT, edge computing y
en general para configurar clusters de Kubernetes en sistemas de pocos
recursos (k3s es por ejemplo la opción más adecuada para usar
Kubernetes en la arquitectura arm). 
            
            ---
            
k3s no es un proyecto oficial de
Kubernetes, sino que lo comenzó a desarrollar la empresa
[Rancher](https://rancher.com/) y hoy en día lo mantiene la [Cloud
Native Computing Foundation](https://www.cncf.io/).
            
            ---

Los pasos para la instalaciónde k3s están disponibles en:

* [https://rancher.com/docs/k3s/latest/en/installation/](https://rancher.com/docs/k3s/latest/en/installation/)
            
            ---

# Conclusión

Aunque existen múltiples opciones de instalación de Kubernetes, en este curso
utilizaremos minikube que es el proyecto más maduro y que consideramos
más adecuado para comenzar y centrarnos directamente en el uso de
Kubernetes, obviando inicialmente los detalles de la instalación de
Kubernetes, que realmente es un proceso complejo y que no es lo más
adecuado para empezar.
            
            ---
            
# Introducción a la instalación de minikube
            
            ---

El "cluster" de k8s que vamos a utilizar en este curso es el de un
solo nodo que va a encargarse de realizar tanto las tareas de master,
con los componentes principales de Kubernetes, como de worker,
ejecutando las cargas de trabajo en contenedores (ya veremos más
adelante que realmente utiliza algo que se llama Pod).
            
            ---

Minikube se distribuye como un programa que se instala en nuestra
máquina física (podría instalarse igualmente en una máquina virtual a
la que tuviésemos acceso completo) y que al ejecutarlo crea una
máquina virtual linux con un cluster de Kubernetes completamente
configurado y listo para su uso. Podemos instalar minikube en nuestra
máquina con sistema linux, windows o mac y en una variedad importante
de sistemas de virtualización, aunque en el curso recomendaremos sólo
algunas combinaciones que hemos probado y que incluyen toda la
funcionalidad necesaria para realizar el curso.
            
            ---

**Nota:** Puede haber interacción si utilizamos más de un
sistema de virtualización en nuestro equipo, por ejemplo, la
utilización en Windows de virtualbox para unas cosas e hyper-v para
minikube, puede dar lugar a problemas, por lo que en general es
recomendable usar un solo sistema de virtualización.
            
            ---

Combinaciones de sistema operativo/virtualización recomendadas para el
curso:

* Linux + KVM
* Linux + VirtualBox
* Windows + HyperV
* Windows + VirtualBox
            
            
          ---
            
            ## Instalación de minikube en linux con KVM

Accedemos a
[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)
y seleccionamos el método que prefiramos para instalar, eligiendo
nuestro sistema operativo, arquitectura, etc.
            
            ---

Minikube se instala, como otras aplicaciones de Go, como un binario
enlazado estáticamente (autoconsistente), que no tiene dependencias de
nada y que tenemos que ubicar en algún directorio del PATH de nuestro
sistema. Veamos en particular la instalación directa del binario en un
sistema linux:
            
            ---

Paso 1: Descargamos como usuario normal y con ayuda de la aplicación
curl, la última versión del binario de minikube (en este caso para
arquitectura x86-64):

    curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
            
            ---

Paso 2: Movemos el binario a un directorio del PATH (lo recomendable
en este caso sería /usr/local/bin/) y establecemos permisos de
ejecución. Todo esto puede hacerse con los comandos `mv` y `chmod`, o
de forma más sencilla con `install`

    sudo install minikube-linux-amd64 /usr/local/bin/minikube
            
            ---

Comprobamos que se ha instalado correctamente con:

    minikube version

    minikube version: v1.24.0
	commit: 76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b
            
            ---

## Creación del cluster de k8s

El siguiente paso consiste en lanzar minikube para que cree el cluster
de Kubernetes de un solo nodo (master+worker). Minikube puede crear
este cluster en diversos sistemas de virtualización o sobre docker, lo
recomendable es visitar la página de
["drivers"](https://minikube.sigs.k8s.io/docs/drivers/) y seleccionar
el método más adecuado para nuestro sistema.
            
            ---

De forma general, se creará el cluster de Kubernetes a través de
minikube, mediante la instrucción:

    minikube start
            
            ---

Aunque de forma más concreta, especificaremos el "driver" a utilizar,
por ejemplo:

    minikube start --driver=kvm2
            
            ---

Esto creará de forma automática una máquina virtual o un contenedor en
el sistema escogido e instalará Kubernetes en ella. Por último, se
configura kubectl si está instalado (el cliente de línea de comandos
de k8s) para que utilice el cluster recién instalado. Podemos ver una
salida típica de la instalación del cluster a continuación:
            
            ---

```
😄  minikube v1.24.0 en Debian 11.2
✨  Using the kvm2 driver based on user configuration
👍  Starting control plane node minikube in cluster minikube
🔥  Creando kvm2 VM (CPUs=2, Memory=3900MB, Disk=20000MB) ...
🐳  Preparando Kubernetes v1.22.3 en Docker 20.10.8...
    ▪ Generating certificates and keys ...
    ▪ Booting up control plane ...
    ▪ Configuring RBAC rules ...
🔎  Verifying Kubernetes components...
    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
🌟  Complementos habilitados: default-storageclass, storage-provisioner
💡  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```
            ---
            
En la última línea de la salida podemos ver que se ha intentado
configurar apropiadamente kubectl, a pesar de que no está instalado en
el equipo, paso que haremos en el siguiente apartado.

Podemos comprobar en cualquier momento el estado de minikube con la
instrucción:

```
minikube status
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```
            ---

## Parada y reinicio de minikube

Podemos parar y volver a arrancar minikube cuando sea preciso, ya que
no se trata de un cluster de k8s en producción, sino de uno instalado
en un equipo convencional. Esto se realiza mediante las instrucciones:
            
            ---

```
minikube stop
✋  Stopping node "minikube"  ...
🛑  1 nodes stopped.
```
            ---

```
minikube start
😄  minikube v1.24.0 en Debian 11.2
✨  Using the kvm2 driver based on existing profile
👍  Starting control plane node minikube in cluster minikube
🔄  Restarting existing kvm2 VM for "minikube" ...
🐳  Preparando Kubernetes v1.22.3 en Docker 20.10.8...
🔎  Verifying Kubernetes components...
    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
🌟  Complementos habilitados: storage-provisioner, default-storageclass
💡  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```
            ---
		  
# Instalación de kubectl en linux
		  
		  ---

**kubectl** es la herramienta de línea de comandos utilizada para
interactuar con la API de Kubernetes. Es por tanto la herramienta
fundamental que vamos a utilizar durante todo el curso para gestionar
nuestros objetos en el cluster recién creado con minikube.
		  
		  ---

kubectl está escrito en Go y de nuevo su instalación es muy simple, ya
que se trata de un binario enlazado estáticamente y sin
dependencias. Las instrucciones para su instalación están disponibles
en la [documentación de k8s](https://kubernetes.io/es/docs/tasks/tools/install-kubectl/). A
continuación veremos algunas de las opciones que tenemos para
instalarlo.

		  ---
		  
## Opción 1. Instalar binario desde el proyecto
		  
		  ---

Al igual que hemos hecho con minikube, podemos descargar el binario
directamente desde la URL del proyecto e instalarlo en
`/usr/local/bin`:

```
curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/kubectl
```

		  ---
		  
Este binario obviamente no se actualiza y tendremos que repetir el
proceso cuando se actualice.

## Opción 2. Instalar desde repositorios no oficiales
		  
		  ---

El término repositorio no oficial se utiliza para aquellos
repositorios que se añaden y que no son los propios de la distribución
que estamos utilizando. En este caso, los repositorios no oficiales
los proporciona el propio proyecto k8s.
		  
		  ---

En el caso de las distribuciones Debian y derivadas, el repositorio es
`https://packages.cloud.google.com/apt/` y en la documentación se
detallan los pasos para instalar `kubectl` a través de apt.
		  
		  ---

La ventaja de este método respecto al anterior es que sí se
actualizará `kubectl` adecuadamente como cualquier otro paquete que
tengamos instalado en nuestra distro.
		  
		  ---

## Opción 3. Instalar desde repositorio oficial

En el caso de Debian, se ha añadido soporte para Kubernetes a partir
de la versión `bullseye` o Debian 11, por lo que si tenemos instalada
esa versión, podemos instalar `kubectl` directamente con apt:

```
sudo apt install kubernetes-client
```

En estos momentos se instala la versión 1.20 de kubectl.
		  
		  ---

## Opción 4. Instalar desde snap

Ubuntu no proporciona de forma directa un paquete con el cliente de
k8s, pero sí lo hace a través de snap, por lo que quienes utilicen
dicho sistema, lo tienen disponible con un simple:

```
sudo snap install kubectl --classic
```
		  
		  ---

## Configuración kubectl

Una vez instalado `kubectl` podemos comprobar que está disponible y cuál es su
versión, con la instrucción:

```
kubectl version
Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.3", GitCommit:"816c97ab8cff8a1c72eccca1026f7820e93e0d25", GitTreeState:"clean", BuildDate:"2022-01-25T21:25:17Z", GoVersion:"go1.17.6", Compiler:"gc", Platform:"linux/amd64"}
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

		  ---
		  
En el caso anterior, estamos utilizando la versión 1.22.2 y nos
informa de que no ha podido conectarse al cluster de Kubernetes con la
configuración por defecto (`localhost:8080`). Es decir, aunque
tengamos kubectl y minikube instalados, el primero no está configurado
todavía para conectarse al cluster de k8s que ejecuta minikube.
		  
		  ---

La solución más sencilla es parar minikube y volverlo a arrancar,
porque de esta manera minikube configurará automáticamente
`kubectl`. Si nos fijamos en la salida de minikube anterior, en la que
no teníamos instalado `kubectl`, aparecía la línea:

```
💡  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
```
		  
		  ---

Pero si lo volvemos a repetir ahora, esa línea no aparecerá y se
configurará `kubectl` para poder usar el cluster que proporciona
minikube. Lo que va a hacer minikube es configurar el fichero
`~/.kube/config` de la siguiente manera:
		  
		  ---

```
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/alberto/.minikube/ca.crt
    extensions:
    - extension:
        last-update: Sun, 30 Jan 2022 20:45:08 CET
        provider: minikube.sigs.k8s.io
        version: v1.24.0
      name: cluster_info
    server: https://192.168.39.115:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    extensions:
    - extension:
        last-update: Sun, 30 Jan 2022 20:45:08 CET
        provider: minikube.sigs.k8s.io
        version: v1.24.0
      name: context_info
    namespace: default
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /home/alberto/.minikube/profiles/minikube/client.crt
    client-key: /home/alberto/.minikube/profiles/minikube/client.key
```

		  ---
		  
		  
Donde en cada caso variará la dirección IP del servidor del cluster
(en este caso la 192.168.39.221) y la ubicación de los ficheros de los
certificados y claves x509 (en este caso en el directorio
`/home/maximo`).
		  
		  ---

Una vez configurado correctamente `kubectl`, podemos repetir el
comando:

```
kubectl version

Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.3", GitCommit:"816c97ab8cff8a1c72eccca1026f7820e93e0d25", GitTreeState:"clean", BuildDate:"2022-01-25T21:25:17Z", GoVersion:"go1.17.6", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.3", GitCommit:"c92036820499fedefec0f847e2054d824aea6cd1", GitTreeState:"clean", BuildDate:"2021-10-27T18:35:25Z", GoVersion:"go1.16.9", Compiler:"gc", Platform:"linux/amd64"}
```

		  ---
		  
Comprobamos que ya aparece la versión del servidor y por
tanto se ha podido conectar con el cluster que gestiona
minikube. Además podemos ejecutar nuestro primer comando propiamente
de `kubectl`:

```
kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
minikube   Ready    control-plane,master   21m   v1.22.3
```
		  
		 ---

Si queremos utilizar el autocompletado, podemos generarlo e
incorporarlo a nuestro entorno con:

```
echo 'source <(kubectl completion bash)' >>~/.bashrc
```

	---
	
Y para poder usarlo en esta misma sesión (no será necesario más
adelante, ya que el fichero .bashrc se lee cada vez que se inicia una
sesión):

```
source ~/.bashrc
```
            
          </textarea>
        </section>
      </div>
    </div>

    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script src="reveal.js/plugin/zoom/zoom.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom],
      });
    </script>
  </body>
</html>
