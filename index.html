<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Kubernetes</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="reveal.js/dist/theme/moon.css" id="theme" />

    <!-- Theme used for syntax highlighted code -->
    <link
      rel="stylesheet"
      href="reveal.js/plugin/highlight/moon.css"
      id="moon-theme"
    />
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section
          data-markdown
          data-separator="-----"
          data-separator-vertical="---"
        >
          <textarea data-template># Implantaci√≥n de aplicaciones web
            
            ---

El protocolo http, o su extensi√≥n https, ha ido convirti√©ndose poco a
poco en el "superprotocolo" de Internet y ha ido desplazando
paulatinamente el uso de otros protocolos.
            
            ---

De igual forma, la mayor
parte del software que se consume hoy en d√≠a se podr√≠a denominar de
forma gen√©rica como aplicaci√≥n web, aunque hay diferencias
importantes sobre la forma de presentarse, ya que no es lo mismo que una persona acceda a una aplicaci√≥n a trav√©s de un navegador, a trav√©s
de una aplicaci√≥n m√≥vil o que quien acceda a la aplicaci√≥n sea una
m√°quina.
            ---

En este curso no podemos entrar en detalle sobre las
caracter√≠sticas de estas aplicaciones web, pero s√≠ en las
caracter√≠sticas que deben tener los sistemas que las ofrecen para que
cumplan con los requisitos esperados.
            
            ---

## Requisitos habituales de las aplicaciones web
            
            ---

Pensemos inicialmente en el caso de una aplicaci√≥n interna de una
empresa que est√° instalada localmente y que los √∫nicos usuarios que
tiene son la plantilla de empleados de la empresa. En ese caso, es
f√°cil determinar los recursos necesarios para que la aplicaci√≥n
funcione de forma adecuada, porque ni el uso de la aplicaci√≥n se
dispara en unos instantes, ni el n√∫mero de empleados de una empresa
var√≠a de forma abrupta.
            
            ---

Por otra parte, las actualizaciones se pueden
hacer en momentos en los que el uso es m√≠nimo y, si es necesario una
interrupci√≥n del servicio, se puede programar para un momento
determinado en que tenga muy poco impacto. 
            
            ---
            
            Las aplicaciones de este
tipo no se suelen modificar habitualmente, sino que lo hacen de forma
bastante espaciada en el tiempo, por lo que los cambios entre una
versi√≥n y otra son significativos. Esto, que podr√≠amos llamar
inform√°tica tradicional, tambi√©n tiene un impacto importante en la
forma de desarrollar las aplicaciones que funcionan bajo este
esquema.
            
            ---

Por otra parte, una aplicaci√≥n web que est√© disponible en Internet,
tiene miles de millones de potenciales usuarios, que la pueden usar
las 24 horas del d√≠a y cualquier d√≠a del a√±o. Esto tiene unas
consecuencias muy importantes, ya que es muy dif√≠cil determinar los
recursos necesarios para prestar servicios a una demanda muy variable
e idealmente, el servicio no puede interrumpirse nunca.
            
            ---
            
¬øEs posible que el mismo sistema se ajuste a una demanda
que puede variar de un usuario a un mill√≥n?, ¬øes posible tener un
sistema siempre actualizado y que a la vez no se pare?, ¬øc√≥mo se
aplican las actualizaciones de software?, ¬øpoco a poco o con grandes
saltos?. Durante este curso, veremos que precisamente esto es lo que
trata de proporcionar Kubernetes.
            
            ---

## Componentes auxiliares de un servicio web
            
            ---

El componente esencial para servir una aplicaci√≥n web es un servidor
web, pero vamos a ver a continuaci√≥n, que para poder proporcionar el
servicio con los requisitos anteriores, debe apoyarse en un n√∫mero
importante de componentes auxiliares. En los siguientes apartados
vamos a ir viendo paso a paso la forma de ir incluyendo diferentes
componentes auxiliares y c√≥mo esta inclusi√≥n va a ir cambiando la arquitectura de los
sistemas que proporcionan el servicio.
            
            ---

### Paso 1. Punto de partida
            
            ---

Supongamos que nuestra organizaci√≥n proporciona tres aplicaciones web
diferentes que son accesibles a trav√©s de las URL:

https://example.com/app1

https://example.com/app2

https://example.com/app3
            
            ---

Estas aplicaciones pueden estar desarrolladas en el mismo lenguaje o en varios diferentes (Python, Java, PHP, etc.), pueden utilizar una base
de datos, almacenamiento auxiliar y como se sirven a trav√©s de https,
es necesario gestionar los certificados x509.
            
            ---

El esquema inicial que pensar√≠amos para proporcionar estas tres
aplicaciones ser√≠a una m√°quina (f√≠sica o virtual) en la que
instalar√≠amos el servidor web, los servidores de aplicaciones (php,
java, ...), el servidor de bases de datos, etc... tal y como aparece en la siguiente imagen:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso1.png" alt="paso1" />
            
            ---

### Paso 2. Servidor de bases de datos separado o independiente
            
            ---

Desde un punto de vista de seguridad, ubicar el servidor de bases de
datos en el mismo equipo que el servidor web es totalmente inadecuado,
ya que el servidor web, por su propia naturaleza debe permitir que
cualquier usuario acceda desde Internet y una vulnerabilidad en este
equipo podr√≠a exponer los datos que se ubican en las bases de datos a
un potencial atacante.
            
            ---
            
Adem√°s, desde el punto de vista del rendimiento
y la disponibilidad, separar los servicios en diferentes equipos hace
que no haya interacciones entre ellos y no compitan por los mismos
recursos.

            ---
            
<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso2.png" alt="paso2" />
            
            ---

### Paso 3. Servidores de aplicaciones en equipos separados
            
            ---

El coste computacional mayor en una aplicaci√≥n web suele recaer en los
servidores de aplicaciones, que son los que ejecutan c√≥digo complejo, mientras que el servidor web se limita a servir el contenido generado
por estos servidores de aplicaciones o los ficheros est√°ticos del sitio web. 

            ---
            
Al servir tres aplicaciones web diferentes desde el mismo
equipo, podemos tener importantes interacciones entre ellas y que un
aumento de uso de una aplicaci√≥n, repercuta negativamente en las
otras. 
            ---
            
            Es por esto, por lo que se puede separar estos servidores de
aplicaci√≥n en equipos dedicados para cada una de ellas. La funci√≥n del
servidor web en este caso, se acerca m√°s a la de un proxy inverso, que
pasa la petici√≥n web a un equipo interno (el servidor de
aplicaciones).
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso3.png" alt="paso3" />
            
            ---

### Paso 4. Cach√© SQL
            
            ---

Los servidores de aplicaciones consultan continuamente a los
servidores de bases de datos y cada consulta conlleva un importante
coste computacional y una ralentizaci√≥n de la respuesta. 
            
            ---
            
            Si la misma
consulta ya se ha realizado antes, se puede acelerar mucho la
velocidad de respuesta con menor coste computacional utilizando un
servicio de cach√© SQL, de manera que los servidores de aplicaciones se
configuran para consultar al servidor cach√©, que servir√° directamente
la respuesta si ya lo ha hecho anteriormente, o consultar√° al servidor
de bases de datos en caso necesario. 
            
            ---
            
            Memcached o redis son dos
opciones muy utilizadas como cach√© SQL.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso4.png"
alt="paso4" />
            
            ---

### Paso 5. Cach√© HTTP
            
            ---

Al igual que se puede cachear la respuesta del servidor de bases de
datos, se puede hacer lo mismo con la del servidor de aplicaciones o
el servidor web. 
            
            ---
            
            Dependiendo del servidor de aplicaciones, se puede
ubicar este componente delante del servidor web o entre √©ste y el
servidor de aplicaciones. Dicho de otro modo, podemos cachear http o
alg√∫n otro protocolo como CGI, WSGI, etc. Un software muy conocido de
cach√© http es varnish.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso5.png"
alt="paso5" />
            
            ---

### Paso 6. Varios servidores de aplicaciones
            
            ---

Si la demanda de alguna de las aplicaciones var√≠a de forma importante,
se puede utilizar escalado horizontal, aumentando el n√∫mero de nodos
de estos servidores de aplicaciones a la demanda de cada momento.
            
            ---
            
            Esto
conlleva dos importantes modificaciones, el almacenamiento entre los
servidores de aplicaci√≥n de la misma aplicaci√≥n tiene que estar
distribuido de forma que garantice el uso concurrente y se deben
repartir las peticiones a los diferentes servidores de aplicaci√≥n a
trav√©s de un balanceador de carga.
            
            ---
            

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso6.png"
alt="paso6" />
            
            ---

### Paso 7. Alta disponibilidad en el resto de componentes
            
            ---

No solo se pueden escalar horizontalmente los servidores de
aplicaciones, sino que si queremos ofrecer realmente alta
disponibilidad en todos los niveles, debemos crear una arquitectura en
la que la disponibilidad nunca dependa de uno solo nodo y el sistema
pueda responder siempre ante incidencias puntuales en cualquier nivel.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso7.png"
alt="paso7" />
            
            ---


### Paso 8. Microservicios y aplicaciones "tradicionales"
            
            ---

Una de las opciones que se considera m√°s adecuada hoy en d√≠a para el
desarrollo y puesta en producci√≥n de aplicaciones web es la utilizaci√≥n de microservicios. Con este enfoque los propios componentes de la aplicaci√≥n se
separan en m√∫ltiples componentes que se ejecutan en nodos
independientes (t√≠picamente contenedores) y se comunican unos con
otros a trav√©s de servicios en red que ofrecen al resto.
            
            ---

Estos microservicios no solo incluir√≠an de forma independiente los
componentes que hemos explicado hasta ahora, sino que principalmente
se refiere a la separaci√≥n de los componentes internos de la
aplicaci√≥n en diferentes microservicios.
           

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso8.png"
alt="paso8" />
            
            ---

### Paso 9. Escalabilidad en los microservicios
            
            ---

Al ofrecer microservicios no podemos tener dependencia de un solo
nodo, por lo que al igual que en los pasos anteriores, se debe ofrecer
la posibilidad de escalar cualquier componente a la demanda y que el
sistema globalmente pueda responder ante cualquier error puntual.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso9.png"
alt="paso9" />
            
            ---

### Paso 10. Microservicios en todas las aplicaciones
            
            ---

En lugar de utilizar microservicios en una aplicaci√≥n, podr√≠amos
utilizarlos en todas, pero manteniendo los componentes auxiliares
gestionados aparte.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso10.png"
alt="paso10" />
            
            ---

### Paso 11. Todo en microservicios

O podr√≠amos tener todo definido internamente en microservicios, tanto
los componentes de cada aplicaci√≥n, como los componentes auxiliares.
            
            ---

<img
src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/paso11.png"
alt="paso11" />
            
            ---

## Contenedores
            
            ---

En parte por lo que hemos explicado aqu√≠, y en parte por las ventajas
que proporciona en el desarrollo de software y en el r√°pido
despliegue, muchos de los componentes que hemos presentado se
ejecutan no sobre m√°quinas virtuales o f√≠sicas, sino que lo hacen
sobre contenedores de aplicaciones tipo docker (hoy en d√≠a se plantean
otras alternativas como podman o containerd, pero no vamos a entrar en
esa explicaci√≥n). 
            
            ---     
            
            
Docker es capaz de gestionar esos contenedores de
forma √°gil y r√°pida, pero no tiene funcionalidad para ejecutar
escenarios tan complejos como los anteriores, que adem√°s se
ejecutar√≠an l√≥gicamente en diferentes nodos f√≠sicos o virtuales (que a
su vez ejecutar√≠an docker para los componentes de la aplicaci√≥n).
            
            ---

## Conclusi√≥n
            
            ---

Esto no son m√°s que un conjunto de componentes y una explicaci√≥n muy
r√°pida de ellos, el orden y la ubicaci√≥n de ellos es variable en
funci√≥n del caso de uso, pero en cualquier caso quer√≠amos presentarlos
aqu√≠ para tener una visi√≥n global de hacia d√≥nde vamos. Algo que
claramente podemos ver es que la gesti√≥n de este tipo de aplicaciones
se convierte pronto en algo muy complejo, por lo que necesitamos
apoyarnos en alg√∫n software que controle y gestione de forma adecuada
estos sistemas tan complejos.
            
            ---
            
            # Docker y su evoluci√≥n hist√≥rica
            
            ---

Docker es una empresa ([Docker Inc.](https://www.docker.com/)) que
desarrolla un software con el mismo nombre, de forma m√°s concreta el software denominado ([docker
engine](https://www.docker.com/products/container-runtime)), que ha
supuesto una revoluci√≥n en el desarrollo de software, muy ligado al
uso de contenedores de aplicaciones, a las aplicaciones web y al
desarrollo √°gil.
            
            ---

Docker permite gestionar contenedores a alto nivel, proporcionando
todas las capas y funcionalidad adicional y, lo m√°s importante de todo,
es que proporciona un nuevo paradigma en la forma de distribuir las
aplicaciones, ya que se crean im√°genes en contenedores que se
distribuyen, de manera que el contenedor que se ha desarrollado es
id√©ntico al que se utiliza en producci√≥n y deja de instalarse la
aplicaci√≥n de forma tradicional.
            
            ---

## Componentes de docker

Docker engine tiene los componentes que a *grosso modo* se presentan a
continuaci√≥n:
            
            ---

<img src="https://github.com/iesgn/curso_kubernetes_cep/raw/main/modulo1/img/docker.png" alt="docker" />

En la imagen se han destacado los componentes que son relevantes desde
el punto de vista de este curso, ya que como veremos m√°s adelante,
docker podr√≠a ser un componente esencial de Kubernetes, pero realmente
no lo es completo, solo containerd y los elementos que √©ste
proporciona lo son, ya que k8s utiliza su propia API, su propia l√≠nea
de comandos y gestiona el almacenamiento y las redes de forma
independiente a docker.
            
            ---

## Evoluci√≥n del proyecto docker
            
            ---

Docker tuvo un enorme √©xito y una gran repercusi√≥n, pero la empresa
que lo desarrolla siempre se ha movido en el dilema de c√≥mo sacar
rendimiento econ√≥mico a su software, que al ser desarrollado bajo
licencia libre, no proporciona beneficio como tal. Este dilema se ha
tratado de resolver con modificaciones en la licencia o con doble
licenciamiento (docker CE y docker EE en estos momentos), pero esto a
su vez ha propiciado que otras empresas desarrollasen alternativas a
docker para no depender en el futuro de una empresa sin un modelo de
negocio claro y ante posibles modificaciones de la licencia libre de
docker.

            ---
            
Los cambios m√°s significativos que han ocurrido en docker se enumeran
a continuaci√≥n:
            
            ---

* [Moby](https://github.com/moby/moby) Docker engine se desarrolla
  ahora como proyecto de software libre independiente de Docker Inc. denomin√°ndose Moby. De este proyecto se surten las distribuciones de
  linux para desarrollar los paquetes docker.io
            
            ---

* [Docker Engine](https://www.docker.com/products/container-runtime)
  Versi√≥n desarrollada por Docker Inc.
            
            ---

* [runC](https://github.com/opencontainers/runc) Componente que
  ejecuta los contenedores a bajo nivel. Actualmente desarrollado por
  OCI
            
            ---

* [containerd](https://github.com/containerd/containerd) Componente
  que ejecuta los contenedores e interact√∫a con las
  im√°genes. Actualmente desarrollado por la CNCF.
            
            ---

## Limitaciones de docker (docker engine)

Docker (docker engine) gestiona completamente la ejecuci√≥n de un
contenedor en un determinado nodo a partir de una imagen, pero no
proporciona toda la funcionalidad que necesitamos para ejecutar
aplicaciones en entornos en producci√≥n.
            
            ---

Existen diferentes preguntas
que nos podemos hacer acerca de esto :
            
            ---

* ¬øQu√© hacemos con los cambios entre versiones?
* ¬øC√≥mo hacemos los cambios en producci√≥n?
* ¬øC√≥mo se balancea la carga entre m√∫ltiples contenedores iguales?
* ¬øC√≥mo se conectan contenedores que se ejecuten en diferentes
demonios de docker?
* ¬øSe puede hacer una actualizaci√≥n de una aplicaci√≥n sin
interrupci√≥n?
* ¬øSe puede variar a demanda el n√∫mero de r√©plicas de un determinado
contenedor?
* ¬øEs posible mover la carga entre diferentes nodos?
            
            ---

Las respuestas a estas preguntas no pueden venir de docker engine, ya
que no es un software desarrollado para eso, tiene que venir de alg√∫n software
que pueda utilizar docker o parte de √©l y que sea capaz de comunicar
m√∫ltiples nodos para proporcionar de forma coordinada estas
funcionalidades. Ese software se conoce de forma gen√©rica como
**orquestador de contenedores**.
            
            ---
           
## Instalaci√≥n de Kubernetes.
            
            ---
## Alternativas para instalaci√≥n simple de k8s
            
            ---

Kubernetes es un software pensado para poner en producci√≥n
aplicaciones m√°s o menos complejas que se ejecutan sobre contenedores,
garantizando su disponibilidad, escalabilidad y actualizaci√≥n sin
interrupciones.
            
            ---

En un entorno en producci√≥n no se instala Kubernetes
en un solo equipo (nodo), sino que creamos un cluster de nodos que
permita garantizar el funcionamiento ininterrumpido de las
aplicaciones incluso en el caso de que uno o varios de los nodos del
cluster tengan alg√∫n tipo de incidencia.
            
            ---

Configurar y actualizar un cluster de Kubernetes es una tarea
compleja, pero existe la posibilidad de instalar de forma f√°cil un
cluster de Kubernetes compuesto por un solo nodo o un conjunto peque√±o
para algunos casos de uso, como en el caso de la instalaci√≥n de un
entorno de desarrollo o aprendizaje, que es precisamente la situaci√≥n
que tenemos en nuestro caso.
            
            ---
            
 Estas instalaciones de Kubernetes no son
adecuadas para entornos en producci√≥n, pero nos permiten utilizar
Kubernetes de forma sencilla, conocer los objetos y atacar la API sin
tener que utilizar una instalaci√≥n m√°s compleja o costosa.
            
            ---

# minikube

Minikube permite desplegar localmente un "cluster" de Kubernetes con
un solo nodo. Minikube es un proyecto oficial de Kubernetes y es
probablemente la soluci√≥n m√°s adecuada para aprender a usar k8s, ya
que es un proyecto maduro y muy sencillo de instalar. Los requisitos
m√≠nimos para instalar minikube en nuestro equipo son:
            
            ---

* 2 CPUs
* 2GiB de memoria
* 20GiB de espacio libre en disco
* Un sistema de virtualizaci√≥n o de contenedores instalado:
  * Docker
  * Hyperkit
  * Hyper-V
  * KVM
  * Parallels
  * Podman
  * VirtualBox
  * VMWare
            
            ---

Minikube instalar√° un nodo de Kubernetes en el sistema de
virtualizaci√≥n/contenedores que prefiramos, siendo unas opciones m√°s adecuadas que otras dependiendo del sistema operativo de nuestro equipo, tal como se muestra
en
[https://minikube.sigs.k8s.io/docs/drivers/](https://minikube.sigs.k8s.io/docs/drivers/). En
versiones recientes, es posible aumentar el n√∫mero de nodos del
cluster de minikube, aunque para el objetivo de este curso no es
necesario y haremos la instalaci√≥n est√°ndar de un solo nodo.
            
            ---

Los detalles para la instalaci√≥n local de minikube los explicamos en
la siguiente secci√≥n, ya que va a ser el m√©todo recomendado para
realizar este curso.
            
            ---

# kubeadm

kubeadm es una soluci√≥n m√°s realista que minikube si se
instala un cluster de Kubernetes con varios nodos. Su instalaci√≥n no es especialmente compleja, pero no est√° tan automatizada
como minikube y necesita m√°s recursos y tiempo para
configurarlo. kubeadm es una opci√≥n muy interesante cuando queremos
ver de forma detallada la diferencia entre lo que se ejecuta en el
nodo controlador y en los nodos workers, que no se puede apreciar en
minikube.
            
            ---

La instalaci√≥n de kubeadm se realiza t√≠picamente en varias m√°quinas
virtuales o varias instancias de nube y dejamos un par de enlaces para
quienes est√©n m√°s interesados en indagar en este software:
            
            ---

* [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
* [https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/](https://www.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/)

            ---
# kind

kind (kubernetes in docker) es un proyecto oficial de Kubernetes m√°s
reciente que los dos anteriores y que permite desplegar un cluster de
Kubernetes con varios nodos sobre docker. Es tambi√©n muy interesante
como opci√≥n de instalaci√≥n local y de forma an√°loga al anterior,
dejamos un par de enlaces para quienes est√©n interesados en probarlo:
            
            ---

* [https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/)
* [https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/](https://www.josedomingo.org/pledin/2021/02/kubernetes-con-kind/)
            
            ---

# k3s

A diferencia de las opciones anteriores, k3s es una distribuci√≥n de
Kubernetes que s√≠ est√° pensada para poner en producci√≥n, pero en unas
circunstancias peculiares como son su uso para IoT, edge computing y
en general para configurar clusters de Kubernetes en sistemas de pocos
recursos (k3s es por ejemplo la opci√≥n m√°s adecuada para usar
Kubernetes en la arquitectura arm). 
            
            ---
            
k3s no es un proyecto oficial de
Kubernetes, sino que lo comenz√≥ a desarrollar la empresa
[Rancher](https://rancher.com/) y hoy en d√≠a lo mantiene la [Cloud
Native Computing Foundation](https://www.cncf.io/).
            
            ---

Los pasos para la instalaci√≥nde k3s est√°n disponibles en:

* [https://rancher.com/docs/k3s/latest/en/installation/](https://rancher.com/docs/k3s/latest/en/installation/)
            
            ---

# Conclusi√≥n

Aunque existen m√∫ltiples opciones de instalaci√≥n de Kubernetes, en este curso
utilizaremos minikube que es el proyecto m√°s maduro y que consideramos
m√°s adecuado para comenzar y centrarnos directamente en el uso de
Kubernetes, obviando inicialmente los detalles de la instalaci√≥n de
Kubernetes, que realmente es un proceso complejo y que no es lo m√°s
adecuado para empezar.
            
            ---
            
# Introducci√≥n a la instalaci√≥n de minikube
            
            ---

El "cluster" de k8s que vamos a utilizar en este curso es el de un
solo nodo que va a encargarse de realizar tanto las tareas de master,
con los componentes principales de Kubernetes, como de worker,
ejecutando las cargas de trabajo en contenedores (ya veremos m√°s
adelante que realmente utiliza algo que se llama Pod).
            
            ---

Minikube se distribuye como un programa que se instala en nuestra
m√°quina f√≠sica (podr√≠a instalarse igualmente en una m√°quina virtual a
la que tuvi√©semos acceso completo) y que al ejecutarlo crea una
m√°quina virtual linux con un cluster de Kubernetes completamente
configurado y listo para su uso. Podemos instalar minikube en nuestra
m√°quina con sistema linux, windows o mac y en una variedad importante
de sistemas de virtualizaci√≥n, aunque en el curso recomendaremos s√≥lo
algunas combinaciones que hemos probado y que incluyen toda la
funcionalidad necesaria para realizar el curso.
            
            ---

**Nota:** Puede haber interacci√≥n si utilizamos m√°s de un
sistema de virtualizaci√≥n en nuestro equipo, por ejemplo, la
utilizaci√≥n en Windows de virtualbox para unas cosas e hyper-v para
minikube, puede dar lugar a problemas, por lo que en general es
recomendable usar un solo sistema de virtualizaci√≥n.
            
            ---

Combinaciones de sistema operativo/virtualizaci√≥n recomendadas para el
curso:

* Linux + KVM
* Linux + VirtualBox
* Windows + HyperV
* Windows + VirtualBox
            
            
          ---
            
            ## Instalaci√≥n de minikube en linux con KVM

Accedemos a
[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)
y seleccionamos el m√©todo que prefiramos para instalar, eligiendo
nuestro sistema operativo, arquitectura, etc.
            
            ---

Minikube se instala, como otras aplicaciones de Go, como un binario
enlazado est√°ticamente (autoconsistente), que no tiene dependencias de
nada y que tenemos que ubicar en alg√∫n directorio del PATH de nuestro
sistema. Veamos en particular la instalaci√≥n directa del binario en un
sistema linux:
            
            ---

Paso 1: Descargamos como usuario normal y con ayuda de la aplicaci√≥n
curl, la √∫ltima versi√≥n del binario de minikube (en este caso para
arquitectura x86-64):

    curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
            
            ---

Paso 2: Movemos el binario a un directorio del PATH (lo recomendable
en este caso ser√≠a /usr/local/bin/) y establecemos permisos de
ejecuci√≥n. Todo esto puede hacerse con los comandos `mv` y `chmod`, o
de forma m√°s sencilla con `install`

    sudo install minikube-linux-amd64 /usr/local/bin/minikube
            
            ---

Comprobamos que se ha instalado correctamente con:

    minikube version

    minikube version: v1.24.0
	commit: 76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b
            
            ---

## Creaci√≥n del cluster de k8s

El siguiente paso consiste en lanzar minikube para que cree el cluster
de Kubernetes de un solo nodo (master+worker). Minikube puede crear
este cluster en diversos sistemas de virtualizaci√≥n o sobre docker, lo
recomendable es visitar la p√°gina de
["drivers"](https://minikube.sigs.k8s.io/docs/drivers/) y seleccionar
el m√©todo m√°s adecuado para nuestro sistema.
            
            ---

De forma general, se crear√° el cluster de Kubernetes a trav√©s de
minikube, mediante la instrucci√≥n:

    minikube start
            
            ---

Aunque de forma m√°s concreta, especificaremos el "driver" a utilizar,
por ejemplo:

    minikube start --driver=kvm2
            
            ---

Esto crear√° de forma autom√°tica una m√°quina virtual o un contenedor en
el sistema escogido e instalar√° Kubernetes en ella. Por √∫ltimo, se
configura kubectl si est√° instalado (el cliente de l√≠nea de comandos
de k8s) para que utilice el cluster reci√©n instalado. Podemos ver una
salida t√≠pica de la instalaci√≥n del cluster a continuaci√≥n:
            
            ---

```
üòÑ  minikube v1.24.0 en Debian 11.2
‚ú®  Using the kvm2 driver based on user configuration
üëç  Starting control plane node minikube in cluster minikube
üî•  Creando kvm2 VM (CPUs=2, Memory=3900MB, Disk=20000MB) ...
üê≥  Preparando Kubernetes v1.22.3 en Docker 20.10.8...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Complementos habilitados: default-storageclass, storage-provisioner
üí°  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```
            ---
            
En la √∫ltima l√≠nea de la salida podemos ver que se ha intentado
configurar apropiadamente kubectl, a pesar de que no est√° instalado en
el equipo, paso que haremos en el siguiente apartado.

Podemos comprobar en cualquier momento el estado de minikube con la
instrucci√≥n:

```
minikube status
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```
            ---

## Parada y reinicio de minikube

Podemos parar y volver a arrancar minikube cuando sea preciso, ya que
no se trata de un cluster de k8s en producci√≥n, sino de uno instalado
en un equipo convencional. Esto se realiza mediante las instrucciones:
            
            ---

```
minikube stop
‚úã  Stopping node "minikube"  ...
üõë  1 nodes stopped.
```
            ---

```
minikube start
üòÑ  minikube v1.24.0 en Debian 11.2
‚ú®  Using the kvm2 driver based on existing profile
üëç  Starting control plane node minikube in cluster minikube
üîÑ  Restarting existing kvm2 VM for "minikube" ...
üê≥  Preparando Kubernetes v1.22.3 en Docker 20.10.8...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Complementos habilitados: storage-provisioner, default-storageclass
üí°  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```
            ---
		  
# Instalaci√≥n de kubectl en linux
		  
		  ---

**kubectl** es la herramienta de l√≠nea de comandos utilizada para
interactuar con la API de Kubernetes. Es por tanto la herramienta
fundamental que vamos a utilizar durante todo el curso para gestionar
nuestros objetos en el cluster reci√©n creado con minikube.
		  
		  ---

kubectl est√° escrito en Go y de nuevo su instalaci√≥n es muy simple, ya
que se trata de un binario enlazado est√°ticamente y sin
dependencias. Las instrucciones para su instalaci√≥n est√°n disponibles
en la [documentaci√≥n de k8s](https://kubernetes.io/es/docs/tasks/tools/install-kubectl/). A
continuaci√≥n veremos algunas de las opciones que tenemos para
instalarlo.

		  ---
		  
## Opci√≥n 1. Instalar binario desde el proyecto
		  
		  ---

Al igual que hemos hecho con minikube, podemos descargar el binario
directamente desde la URL del proyecto e instalarlo en
`/usr/local/bin`:

```
curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/kubectl
```

		  ---
		  
Este binario obviamente no se actualiza y tendremos que repetir el
proceso cuando se actualice.

## Opci√≥n 2. Instalar desde repositorios no oficiales
		  
		  ---

El t√©rmino repositorio no oficial se utiliza para aquellos
repositorios que se a√±aden y que no son los propios de la distribuci√≥n
que estamos utilizando. En este caso, los repositorios no oficiales
los proporciona el propio proyecto k8s.
		  
		  ---

En el caso de las distribuciones Debian y derivadas, el repositorio es
`https://packages.cloud.google.com/apt/` y en la documentaci√≥n se
detallan los pasos para instalar `kubectl` a trav√©s de apt.
		  
		  ---

La ventaja de este m√©todo respecto al anterior es que s√≠ se
actualizar√° `kubectl` adecuadamente como cualquier otro paquete que
tengamos instalado en nuestra distro.
		  
		  ---

## Opci√≥n 3. Instalar desde repositorio oficial

En el caso de Debian, se ha a√±adido soporte para Kubernetes a partir
de la versi√≥n `bullseye` o Debian 11, por lo que si tenemos instalada
esa versi√≥n, podemos instalar `kubectl` directamente con apt:

```
sudo apt install kubernetes-client
```

En estos momentos se instala la versi√≥n 1.20 de kubectl.
		  
		  ---

## Opci√≥n 4. Instalar desde snap

Ubuntu no proporciona de forma directa un paquete con el cliente de
k8s, pero s√≠ lo hace a trav√©s de snap, por lo que quienes utilicen
dicho sistema, lo tienen disponible con un simple:

```
sudo snap install kubectl --classic
```
		  
		  ---

## Configuraci√≥n kubectl

Una vez instalado `kubectl` podemos comprobar que est√° disponible y cu√°l es su
versi√≥n, con la instrucci√≥n:

```
kubectl version
Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.3", GitCommit:"816c97ab8cff8a1c72eccca1026f7820e93e0d25", GitTreeState:"clean", BuildDate:"2022-01-25T21:25:17Z", GoVersion:"go1.17.6", Compiler:"gc", Platform:"linux/amd64"}
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

		  ---
		  
En el caso anterior, estamos utilizando la versi√≥n 1.22.2 y nos
informa de que no ha podido conectarse al cluster de Kubernetes con la
configuraci√≥n por defecto (`localhost:8080`). Es decir, aunque
tengamos kubectl y minikube instalados, el primero no est√° configurado
todav√≠a para conectarse al cluster de k8s que ejecuta minikube.
		  
		  ---

La soluci√≥n m√°s sencilla es parar minikube y volverlo a arrancar,
porque de esta manera minikube configurar√° autom√°ticamente
`kubectl`. Si nos fijamos en la salida de minikube anterior, en la que
no ten√≠amos instalado `kubectl`, aparec√≠a la l√≠nea:

```
üí°  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
```
		  
		  ---

Pero si lo volvemos a repetir ahora, esa l√≠nea no aparecer√° y se
configurar√° `kubectl` para poder usar el cluster que proporciona
minikube. Lo que va a hacer minikube es configurar el fichero
`~/.kube/config` de la siguiente manera:
		  
		  ---

```
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/alberto/.minikube/ca.crt
    extensions:
    - extension:
        last-update: Sun, 30 Jan 2022 20:45:08 CET
        provider: minikube.sigs.k8s.io
        version: v1.24.0
      name: cluster_info
    server: https://192.168.39.115:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    extensions:
    - extension:
        last-update: Sun, 30 Jan 2022 20:45:08 CET
        provider: minikube.sigs.k8s.io
        version: v1.24.0
      name: context_info
    namespace: default
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /home/alberto/.minikube/profiles/minikube/client.crt
    client-key: /home/alberto/.minikube/profiles/minikube/client.key
```

		  ---
		  
		  
Donde en cada caso variar√° la direcci√≥n IP del servidor del cluster
(en este caso la 192.168.39.221) y la ubicaci√≥n de los ficheros de los
certificados y claves x509 (en este caso en el directorio
`/home/maximo`).
		  
		  ---

Una vez configurado correctamente `kubectl`, podemos repetir el
comando:

```
kubectl version

Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.3", GitCommit:"816c97ab8cff8a1c72eccca1026f7820e93e0d25", GitTreeState:"clean", BuildDate:"2022-01-25T21:25:17Z", GoVersion:"go1.17.6", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.3", GitCommit:"c92036820499fedefec0f847e2054d824aea6cd1", GitTreeState:"clean", BuildDate:"2021-10-27T18:35:25Z", GoVersion:"go1.16.9", Compiler:"gc", Platform:"linux/amd64"}
```

		  ---
		  
Comprobamos que ya aparece la versi√≥n del servidor y por
tanto se ha podido conectar con el cluster que gestiona
minikube. Adem√°s podemos ejecutar nuestro primer comando propiamente
de `kubectl`:

```
kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
minikube   Ready    control-plane,master   21m   v1.22.3
```
		  
		 ---

Si queremos utilizar el autocompletado, podemos generarlo e
incorporarlo a nuestro entorno con:

```
echo 'source <(kubectl completion bash)' >>~/.bashrc
```

	---
	
Y para poder usarlo en esta misma sesi√≥n (no ser√° necesario m√°s
adelante, ya que el fichero .bashrc se lee cada vez que se inicia una
sesi√≥n):

```
source ~/.bashrc
```
            
          </textarea>
        </section>
      </div>
    </div>

    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script src="reveal.js/plugin/zoom/zoom.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom],
      });
    </script>
  </body>
</html>
